{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgXmrcFEGdyA",
        "outputId": "ceb6bde2-72cf-482a-f9c3-890cc97a5465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoCgjBsAslte",
        "outputId": "7e16824e-a889-4b22-c48e-df1bf2eb6a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-AM7USjyaVI8ctWcPRZ9GIabkr9vh0\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"I apologize, but I don't have enough information to provide an accurate answer. Could you please specify which hike you are referring to?\",\n",
            "        \"role\": \"assistant\"\n",
            "      },\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1729835372,\n",
            "  \"model\": \"gpt-35-turbo-16k\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 27,\n",
            "    \"prompt_tokens\": 31,\n",
            "    \"total_tokens\": 58\n",
            "  },\n",
            "  \"prompt_filter_results\": [\n",
            "    {\n",
            "      \"prompt_index\": 0,\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"jailbreak\": {\n",
            "          \"filtered\": false,\n",
            "          \"detected\": false\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://openairesourceorion.openai.azure.com/\")\n",
        "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-35-turbo-16k\")\n",
        "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"f02d35d5f4754dc0a431e7f35d80bbb1\")\n",
        "\n",
        "# Initialize Azure OpenAI client with key-based authentication\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=endpoint,\n",
        "    api_key=subscription_key,\n",
        "    api_version=\"2024-05-01-preview\",\n",
        ")\n",
        "\n",
        "# Prepare the chat prompt\n",
        "chat_prompt = [\n",
        "{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"You are an AI assistant that helps people find information.\"\n",
        "},\n",
        "                {\"role\":\"user\",\n",
        "                 \"content\":\"How difficult is the second hike you suggested?\"\n",
        "                 }\n",
        "]\n",
        "\n",
        "# Include speech result if speech is enabled\n",
        "speech_result = chat_prompt\n",
        "\n",
        "# Generate the completion\n",
        "completion = client.chat.completions.create(\n",
        "    model=deployment,\n",
        "    messages=speech_result,\n",
        "    max_tokens=800,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=None,\n",
        "    stream=False\n",
        ")\n",
        "\n",
        "print(completion.to_json())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t2eAKmzGRtH",
        "outputId": "940430b2-9b07-4549-f01c-b03680c71f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I apologize, but I don't have enough information to provide an accurate answer. Could you please specify which hike you are referring to?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://openairesourceorion.openai.azure.com/\")\n",
        "deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o-mini-2024-07-18-OrionicFineTune\")\n",
        "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"f02d35d5f4754dc0a431e7f35d80bbb1\")\n",
        "\n",
        "# Initialize Azure OpenAI client with key-based authentication\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=endpoint,\n",
        "    api_key=subscription_key,\n",
        "    api_version=\"2024-05-01-preview\",\n",
        ")\n",
        "\n",
        "system_message =  \"\"\"\n",
        "\n",
        "    I am a hiking enthusiast named Forest who helps people discover hikes in their area.\n",
        "    If no area is specified, I will default to near Rainier National Park.\n",
        "    I will then provide three suggestions for nearby hikes that vary in length.\n",
        "    I will also share an interesting fact about the local nature on the hikes when making a recommendation\n",
        ".\n",
        "    \"\"\"\n",
        "language = input(\"Enter Language Preference example like java, python: \")\n",
        "\n",
        "if language ==\"python\":\n",
        "  system_message = \"you are an assistant for learning python\"\n",
        "elif language == \"java\":\n",
        "  system_message = \"you are an assistant for learning java\"\n",
        "\n",
        "# Prepare the chat prompt\n",
        "chat_history = [{\"role\":\"system\",\"content\":system_message}]\n",
        "\n",
        "while True:\n",
        "\n",
        "  input_text = input(\"Enter Your Prompt: \")\n",
        "\n",
        "  if input_text.lower() == \"quit\":\n",
        "    break\n",
        "  if len(input_text)==0:\n",
        "    print(\"Give Your Input Prompt: \")\n",
        "\n",
        "  chat_history.append({'role':\"user\",\"content\":input_text})\n",
        "\n",
        "  # Include speech result if speech is enabled\n",
        "  speech_result = chat_history\n",
        "\n",
        "  # Generate the completion\n",
        "  completion = client.chat.completions.create(\n",
        "      model=deployment,\n",
        "      messages=speech_result,\n",
        "      max_tokens=800,\n",
        "      temperature=0.7,\n",
        "      top_p=0.95,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=None,\n",
        "      stream=False\n",
        "  )\n",
        "\n",
        "\n",
        "  print(completion.choices[0].message.content)\n",
        "  chat_history.append({'role':\"assistant\",\"content\":completion.choices[0].message.content})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i15sScunIlXE",
        "outputId": "9a777704-1d11-4abf-d4d2-a111805a96eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Language Preference example like java, python: python\n",
            "Enter Your Prompt: write a basic code to define a def function\n",
            "Certainly! Here's a basic example of how to define a function in Python using the `def` keyword:\n",
            "\n",
            "```python\n",
            "def greet(name):\n",
            "    \"\"\"This function greets a person with their name.\"\"\"\n",
            "    print(f\"Hello, {name}!\")\n",
            "\n",
            "# Example of calling the function\n",
            "greet(\"Alice\")\n",
            "```\n",
            "\n",
            "In this code:\n",
            "\n",
            "- We define a function named `greet` that takes one parameter, `name`.\n",
            "- Inside the function, it prints a greeting message.\n",
            "- Finally, we call the function with the argument `\"Alice\"` to see the output.\n",
            "Enter Your Prompt: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-ai-textanalytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7dalPKRSm7m",
        "outputId": "8124e3f9-9245-4334-ba78-6fa2f342c0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-ai-textanalytics\n",
            "  Downloading azure_ai_textanalytics-5.3.0-py3-none-any.whl.metadata (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.24.0 (from azure-ai-textanalytics)\n",
            "  Downloading azure_core-1.31.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting azure-common~=1.1 (from azure-ai-textanalytics)\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting isodate<1.0.0,>=0.6.1 (from azure-ai-textanalytics)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from azure-ai-textanalytics) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2024.8.30)\n",
            "Downloading azure_ai_textanalytics-5.3.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.6/298.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Downloading azure_core-1.31.0-py3-none-any.whl (197 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.4/197.4 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: azure-common, isodate, azure-core, azure-ai-textanalytics\n",
            "Successfully installed azure-ai-textanalytics-5.3.0 azure-common-1.1.28 azure-core-1.31.0 isodate-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# This example requires environment variables named \"AZURE_AI_KEY\" and \"ENDPOINT_TO_CALL_LANGUAGE_API\"\n",
        "key = os.getenv(\"AZURE_LANGUAGE_KEY\",'dcca817a3853408b9708e18528b8d383')\n",
        "endpoint = os.getenv(\"AZURE_LANGUAGE_ENDPOINT\",'https://ai-orion547816808486.cognitiveservices.azure.com/')\n",
        "\n",
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# Authenticate the client using your key and endpoint\n",
        "def authenticate_client():\n",
        "    ta_credential = AzureKeyCredential(key)\n",
        "    text_analytics_client = TextAnalyticsClient(\n",
        "            endpoint=endpoint,\n",
        "            credential=ta_credential)\n",
        "    return text_analytics_client\n",
        "\n",
        "client = authenticate_client()\n",
        "\n",
        "# Example method for summarizing text\n",
        "def sample_extractive_summarization(client):\n",
        "    from azure.core.credentials import AzureKeyCredential\n",
        "    from azure.ai.textanalytics import (\n",
        "        TextAnalyticsClient,\n",
        "        ExtractiveSummaryAction\n",
        "    )\n",
        "\n",
        "    document = [\n",
        "        \"The extractive summarization feature uses natural language processing techniques to locate key sentences in an unstructured text document. \"\n",
        "        \"These sentences collectively convey the main idea of the document. This feature is provided as an API for developers. \"\n",
        "        \"They can use it to build intelligent solutions based on the relevant information extracted to support various use cases. \"\n",
        "        \"Extractive summarization supports several languages. It is based on pretrained multilingual transformer models, part of our quest for holistic representations. \"\n",
        "        \"It draws its strength from transfer learning across monolingual and harness the shared nature of languages to produce models of improved quality and efficiency. \"\n",
        "    ]\n",
        "\n",
        "    poller = client.begin_analyze_actions(\n",
        "        document,\n",
        "        actions=[\n",
        "            ExtractiveSummaryAction(max_sentence_count=4)\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    document_results = poller.result()\n",
        "    for result in document_results:\n",
        "        extract_summary_result = result[0]  # first document, first result\n",
        "        if extract_summary_result.is_error:\n",
        "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
        "                extract_summary_result.code, extract_summary_result.message\n",
        "            ))\n",
        "        else:\n",
        "            print(\"Summary extracted: {}\".format(\n",
        "                \" \".join([sentence.text for sentence in extract_summary_result.sentences]))\n",
        "            )\n",
        "\n",
        "sample_extractive_summarization(client)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWpuK5VmL9Dr",
        "outputId": "30f0ef83-887d-4626-e73c-76e43b040938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary extracted: The extractive summarization feature uses natural language processing techniques to locate key sentences in an unstructured text document. This feature is provided as an API for developers. Extractive summarization supports several languages. It is based on pretrained multilingual transformer models, part of our quest for holistic representations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h9MmUbU2S2fp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}