{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the required libraries"
      ],
      "metadata": {
        "id": "ZbyTSnFrwrRf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivoSQIm6wo9g",
        "outputId": "178d480e-f17d-4540-a526-a2c4d7a67f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.66.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the pipeline"
      ],
      "metadata": {
        "id": "xhKHnsBTxMPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "hi-Ofn0z1o7n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-1"
      ],
      "metadata": {
        "id": "A727Pij-1ukk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " classifier = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UNZAFgrFbK5",
        "outputId": "bf59ccae-787e-4f4b-ae61-1244a3c318f5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the following code\n",
        "def get_sentiment(sentences:list):\n",
        "    sentiment = classifier(sentences)\n",
        "    print(\"Sentences Sentimensts::\", sentiment)\n",
        "    return sentiment"
      ],
      "metadata": {
        "id": "35hgMCdKxdiU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['My favorite bar in town love the live music and the martinis - fave is the strawberry shortcake!',\n",
        "             'BED BUGS!!! Horrible place! DO NOT STAY HERE!! Stayed here for a wedding we attended.',\n",
        "             'This was by far the worst hotel experience I''ve ever had.',\n",
        "             'AVOID THIS PLACE LIKE THEY SERVE SALMONELLA!',\n",
        "             'A great independent music store.  Really good selection',\n",
        "             'The best pawn shop in Las Vegas',\n",
        "             'This place is GREAT! Got rid of some jewelry I never wear and they got me the beat price for it.']\n",
        "\n",
        "scores = get_sentiment(sentences)\n",
        "print(scores)\n",
        "for i in range(len(sentences)):\n",
        "   print(\"Sentence : \" + sentences[i])\n",
        "   print(\"Label ::\" + scores[i].get('label') + \"  ;  \" +\"Score::\" + str(scores[i].get('score')))"
      ],
      "metadata": {
        "id": "P2Z6XSugy9o0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07351f0-d91c-4c8d-fc77-778de00d6e5d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences Sentimensts:: [{'label': 'POSITIVE', 'score': 0.9992315769195557}, {'label': 'NEGATIVE', 'score': 0.9993444085121155}, {'label': 'NEGATIVE', 'score': 0.9997850060462952}, {'label': 'NEGATIVE', 'score': 0.9995777010917664}, {'label': 'POSITIVE', 'score': 0.9998502731323242}, {'label': 'POSITIVE', 'score': 0.9998127818107605}, {'label': 'POSITIVE', 'score': 0.9998098015785217}]\n",
            "[{'label': 'POSITIVE', 'score': 0.9992315769195557}, {'label': 'NEGATIVE', 'score': 0.9993444085121155}, {'label': 'NEGATIVE', 'score': 0.9997850060462952}, {'label': 'NEGATIVE', 'score': 0.9995777010917664}, {'label': 'POSITIVE', 'score': 0.9998502731323242}, {'label': 'POSITIVE', 'score': 0.9998127818107605}, {'label': 'POSITIVE', 'score': 0.9998098015785217}]\n",
            "Sentence : My favorite bar in town love the live music and the martinis - fave is the strawberry shortcake!\n",
            "Label ::POSITIVE  ;  Score::0.9992315769195557\n",
            "Sentence : BED BUGS!!! Horrible place! DO NOT STAY HERE!! Stayed here for a wedding we attended.\n",
            "Label ::NEGATIVE  ;  Score::0.9993444085121155\n",
            "Sentence : This was by far the worst hotel experience Ive ever had.\n",
            "Label ::NEGATIVE  ;  Score::0.9997850060462952\n",
            "Sentence : AVOID THIS PLACE LIKE THEY SERVE SALMONELLA!\n",
            "Label ::NEGATIVE  ;  Score::0.9995777010917664\n",
            "Sentence : A great independent music store.  Really good selection\n",
            "Label ::POSITIVE  ;  Score::0.9998502731323242\n",
            "Sentence : The best pawn shop in Las Vegas\n",
            "Label ::POSITIVE  ;  Score::0.9998127818107605\n",
            "Sentence : This place is GREAT! Got rid of some jewelry I never wear and they got me the beat price for it.\n",
            "Label ::POSITIVE  ;  Score::0.9998098015785217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-2"
      ],
      "metadata": {
        "id": "3l4zUZfN1xEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the following definition\n",
        "classifier = pipeline('question-answering')\n",
        "def get_answers(context:str, question:str):\n",
        "   res = classifier(question, context)\n",
        "   return res['answer']"
      ],
      "metadata": {
        "id": "y0qIIMu41-9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc825cd9-c82a-4549-9ecd-7d21515a1e0c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"My name is Deeparani, I live in Chennai\"\n",
        "question = \"What is my name?\"\n",
        "answer = get_answers(context, question)\n",
        "print(\"Question : \" + question)\n",
        "print(\"Answer : \" + answer )"
      ],
      "metadata": {
        "id": "dG3ofLM-2PpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f2ab2d-5cbc-470d-c0c0-e25779d0fa20"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question : What is my name?\n",
            "Answer : Deeparani\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-3"
      ],
      "metadata": {
        "id": "OHWm4z8k3hi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_NER(sentences):\n",
        "  classifier = pipeline(\"ner\", grouped_entities=True)\n",
        "  NER_scores = classifier(sentences)\n",
        "  return NER_scores"
      ],
      "metadata": {
        "id": "RTeCvXIE3jss"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"My name is Sarah and I live in London\"]\n",
        "NER_scores = get_NER(sentences)\n",
        "print(\"NER Analysis of Sentences ::: \", NER_scores)\n",
        "for i in range(0, len(NER_scores)):\n",
        "  if type(NER_scores[i]) is list:\n",
        "    for j in range(0, len(NER_scores[i])):\n",
        "      print(\"Sentence ::: \",sentences[i], \",\\n Word ::: \", NER_scores[i][j].get('word'),\", Label ::: \",NER_scores[i][j].get('entity_group'),\", Score ::: \",NER_scores[i][j].get('score'))\n",
        "  else:\n",
        "    print(\"Sentence ::: \",sentences[i], \",\\n Word ::: \", NER_scores[i][j].get('word'),\", Label ::: \",NER_scores[i].get('entity_group'),\", Score ::: \",NER_scores[i].get('score'))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKbZVQQvW77t",
        "outputId": "643ed86a-f333-47a7-e70a-97dbbf31901b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NER Analysis of Sentences :::  [[{'entity_group': 'PER', 'score': 0.9982994, 'word': 'Sarah', 'start': 11, 'end': 16}, {'entity_group': 'LOC', 'score': 0.9983972, 'word': 'London', 'start': 31, 'end': 37}]]\n",
            "Sentence :::  My name is Sarah and I live in London ,\n",
            " Word :::  Sarah , Label :::  PER , Score :::  0.9982994\n",
            "Sentence :::  My name is Sarah and I live in London ,\n",
            " Word :::  London , Label :::  LOC , Score :::  0.9983972\n"
          ]
        }
      ]
    }
  ]
}